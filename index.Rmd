---
title: "Fundamental Techniques"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
---

# Intro {.sidebar data-width=300}

This dashboard covers the course materials for the course 
[***Fundamental Techniques in Data Science with R***][ftds]

---

Course Coordinator: [Laura Boeschoten](https://www.uu.nl/medewerkers/LBoeschoten) <br>
Lecture Instructor: [Kyle Lang](https://www.kylemlang.com) <br>
WG Instructor: [Laura Boeschoten](https://www.uu.nl/medewerkers/LBoeschoten) <br>
WG Instructor: [Rianne Kraakman](https://www.uu.nl/staff/AMKraakman) <br>
WG Instructor: [Anastasia Giachanou](http://www.giachanou.com/) <br>
Study load: 7.5 ECTS <br>
Assessment: Assignments and Exam <br>
[Course SurfDrive folder][sd]

---

| What?   | When?               | Where?                  |
|---------|---------------------|-------------------------|
|         |                     |                         |
| Lecture | 2021-11-15<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-11-18<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-11-18<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-11-18<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-11-22<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-11-25<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-11-25<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-11-25<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-11-29<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-02<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-02<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-02<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-12-06<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-09<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-09<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-09<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-12-13<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-16<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-16<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-16<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-12-20<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-23<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-23<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-23<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-01-10<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-01-13<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-01-13<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-01-13<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-01-17<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-01-20<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-01-20<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-01-20<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Exam    | 2021-01-26<br>19:00 | Educatorium<br>Theatron |

---

# Quick Overview

## Column 1 {data-width=400}

### 

In nine weeks, you will learn the basics of data handling with R and details 
about regression techniques in the context of statistical inference. We will 
also cover the connection between these concepts and research philosophy. During 
every lecture, we will cover a different theoretical topic. In addition to the 
lectures, there will also be a weekly computer lab exercise that connects the 
statistical theory to practice. You will also attend weekly workgroup meetings 
wherein you will work on solving motivating, real-world case studies. 

### Assignment and Grading

The final grade is computed as follows

| Grade Component | Weight |
|:-------|:------|
| Linear Regression Assignment | 25% |
| Logistic Regression Assignment | 25% |
| Written Exam | 50% |

In addition to the grade components listed above, you will also do `R` exercises 
for the first 7 weeks of the course. These exercises will develop the skills 
needed to successfully complete the assignments. 

To pass the course:

1. Your final exam grade must be 5.5 or higher
1. Both of your assignments grades must be 5.5 or higher

## Column 2 {data-width=400}

### Schedule

| Week # | Topic | `R` Exercise | Workgroup | Reading |
|-|---|----|----|--|
| 1 | The elemental building blocks of `R` | Assigning values to objects; Creating vectors, matrices, data frames, and lists | Receive instructions and form groups; Locate a data set for predictive modeling | |
| 2 | Data manipulation; Least squares | Data manipulation; Using pipes to simplify workflows | Get approval for data; Beginning data processing, cleaning, and exploration; Formulate a research hypothesis | |
| 3 | Linear model 1; Data visualization | The `lm()` function in `R`; Visualizing bivariate relations | Specify a linear model; Fit your defined model | [ISL][isl] 3.1 & 6.1, [Blog Post 1](https://thestatsgeek.com/2014/01/25/r-squared-and-goodness-of-fit-in-linear-regression/), [Blog Post 2](https://thestatsgeek.com/2013/10/28/r-squared-and-adjusted-r-squared/), [Lecture Notes](http://www.mit.edu/~6.s085/notes/lecture3.pdf) |
| 4 | Linear model 2; Assumptions; Diagnostics | Investigating the assumptions of the linear model | Check the assumptions of your model; Use your model to test your hypotheses; Continue the project in `rmarkdown` | [ISL][isl] 3.2 -- 3.4 |
| 5 | Model building; Prediction; Cross-validation | Tying the analytic pieces together into a full regression analysis | Evaluate and, if possible, improve your model; **Prepare Assignment 1; Evaluate the final linear model on your own data** | [ISL][isl] 5.1, [Document](wk5/literature/Example_CVlm.pdf) |
| 6 | Generalized linear model; Logistic regression 1 | The `glm()` function in `R`; Logistic regression modeling; Classification | Formulate a research hypothesis and define a logistic model; Fit your defined model | [ISL][isl] 4.1 -- 4.3 (except 4.3.5), [Webpage](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/) |
| 7 | Logistic regression 2 | Finish exercise from last week | Check the assumptions of your model; Use your model to test your hypotheses | [Webpage](https://stats.idre.ucla.edu/r/dae/logit-regression/)
| 8 | Summary, catch-up, and questions | None | Evaluate and, if possible, improve your model; **Prepare Assignment 2; Evaluate the final logistic model on your own data** |

<!----------------------------------------------------------------------------->

# Course Manual

## Column 1

### Course Description

Regression techniques are widely used to quantify the relationship between two 
or more variables, and investigating such relations is common in data science. 
Linear and logistic regression are well-established and powerful 
techniques for analyzing the relations between a set of (predictor) variables 
and a single (outcome) variable. However, you must understand how and when it is 
appropriate to apply these regression techniques before you can use them in any 
beneficial way. In this course, you will learn exactly that: how and when to 
apply linear and logistic regression with the statistical software package `R`. 
 
This course gives students a new set of tools that they can apply to real-world 
data to explore interesting issues and problems. The course will introduce 
students to the principles of analytic data science, linear and 
logistic regression, and the basics of statistical learning. These techniques 
will be presented in the context of estimation, testing, and prediction. 
Students will learn to think carefully and critically about statistical 
inference, quantifying uncertainty, and measuring the accuracy of statistical 
estimates. Students will also develop fundamental `R` programming skills and 
will gain experience with `tidyverse`: visualizing data with `ggplot2` and 
performing basic data wrangling with `dplyr`. This course will prepare students 
for basic research tasks (e.g. junior researcher or research assistant) or 
further education in research, such as a (research) Master program. 

### Assignments

Students will form groups to work on two assignments. Students will need to 
perform calculations and write `R` code for these assignments. All work must be 
combined into an understandable and insightful `R` project and must be 
submitted to the [Surfdrive file drop environment][sd]. 

Each assignment will be graded on the quality of the following components:

1. The methodological application
1. The model evaluation and assumption checking
1. The code and scripts 

### Grading

Students will be evaluated on the following aspects:
 
1. Apply and interpret the basic methodological and statistical concepts 
underlying predictive and/or inferential research.

   a. Explain concepts from inferential statistics, such as probability, 
   inference, and modeling; apply these concepts in practice. 
   a. Make an informed choice of research designs that are suitable for 
   regression analyses.
   a. Apply and explain the choice of techniques for investigating data problems.
   a. Apply and explain the concepts of linearity and non-linearity.
   a. Interpret statistical software output, and report software output 
   following APA reporting guidelines.
   a. Explain and conceptualize statistical inference and its relation to 
   statistical theory.
   a. Perform the different steps of solving basic regression analysis problems 
   and report on these steps.
   
   <br>
   
2. Apply and interpret important techniques in linear and logistic regression 
analysis.

   a. Perform, interpret, and evaluate quantitative (causal) analyses on data 
   with the statistical software platform `R`.
   a. Perform analyses in statistical software.
 
### Relation between Assessment and Objective

In this course, skills and knowledge are evaluated in three separate ways:

- The exam evaluates the knowledge of methodological and statistical concepts 
(learning goals 1a, 1d, 1f), as well as the application of these concepts to 
research scenarios (learning goals 1b and 1c). During the exam students will 
need to interpret statistical software output (learning goal 1e).

- The practical labs test if the student has sufficient skills to solve basic 
analysis problems and execute quantitative analyses on real-life data sets 
(learning goals 2a and 2b).

- The workgroups focus on applying the newly gained knowledge and skills to 
solving relevant data analysis problems and reporting on the steps taken to 
obtain a solution (learning goal 1g).

<!----------------------------------------------------------------------------->

# Preparation

## Column 1

###

Hello All, 

This semester, you will participate in the **Fundamental Techniques in Data 
Science with `R`** course at Utrecht University. In this course, you will use 
both `R` and `RStudio`. The below steps guide you through installing both `R` 
and `RStudio`. Please do so before the first meeting. 

Regards,  
Instructor Team

### **System requirements**

Bring a laptop computer to the course and make sure that you have full write 
access and administrator rights on the machine. We will explore programming and 
compiling in this course, so you will need full access to your machine. Some 
corporate laptops come with limited access for their users, I therefore advise 
you to bring a personal laptop to the workgroup meetings. 

### **1. Install `R`**

You can obtain a copy of `R` [here](https://cran.r-project.org). We won't use 
`R` directly in the course. Rather, we'll call `R` through `RStudio`. Therefore, 
you also need to install `RStudio`. 

### **2. Install `RStudio` Desktop**

`RStudio` is an Integrated Development Environment (IDE) for `R`. You can 
download `RStudio` as stand-alone software [here](https://www.rstudio.com/products/rstudio/download/#download). 
The free and open-source `RStudio Desktop` version is sufficient.

### **3. Start RStudio and install the following packages. **

Open `RStudio`, and copy-paste the following lines of code into the console 
window to execute them.

- If nothing happens after you paste the code, try hitting the "Enter/Return" 
key.

```{r eval = FALSE, echo = TRUE}
install.packages(c("ggplot2", 
                   "tidyverse", 
                   "magrittr", 
                   "micemd", 
                   "jomo", 
                   "pan", 
                   "lme4", 
                   "knitr", 
                   "rmarkdown", 
                   "plotly", 
                   "ggplot2", 
                   "shiny", 
                   "devtools", 
                   "boot", 
                   "class", 
                   "car", 
                   "MASS", 
                   "ggplot2movies", 
                   "ISLR", 
                   "DAAG", 
                   "mice"), 
                 dependencies = TRUE)
```

If you are not sure where to paste the code, use the following figure to 
identify the console:

<center>
  <img src="images/console.png" alt="HTML5 Icon" width = 70%>
</center>

When you are asked the following:

```{r eval = FALSE, echo = TRUE}
Do you want to install from sources the package which needs 
compilation? (Yes/no/cancel)
```

Type `Yes` in the console, and press the "Enter/Return" key (or click the 
corresponding button if the question presents as a dialog box). 

## Column 2

### **What if the steps to the left do not work for me?**

If the suggested steps fail or you have insufficient rights on your machine, you 
can use the following web-based solutions. 

1. Open a free account on [rstudio.cloud](https://rstudio.cloud). 

   - You can run your own cloud-based `RStudio` environment there.
   
<br>

2. Use Utrecht University's [MyWorkPlace](https://myworkplace.uu.nl/). 

   - You will have access to `R` and `RStudio` there. When you start a new 
   MyWorkPlace session, you may need to (re)install packages. 

Naturally, you will need internet access to use these services. 

<!----------------------------------------------------------------------------->

# Week 1

## Column 1

### Lecture (Monday)

Today's lecture is about the elemental building blocks of `R`. We will discuss 
what `R` actually is, why we use `RStudio`, how to 'speak' `R`, and how to work 
with `R` objects. 

You can find the lecture slides [here](wk1/lecture/lecture1.html)

#### Videos

Below, you can find recordings of the residual lecture content that we were not 
able to cover in the live lecture.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/xhPNgtj8eBY" 
        title="Lecture 1 Extra (Part 1)" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>
        
<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/XjoTxUp6YxE" 
        title="Lecture 1 Extra (Part 1)" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)
        
You should attend all workgroup meetings; however, **today's meeting is vital**! 
We will form groups, and we will discuss the assignments and expectations for 
your work in this course. You will also locate a dataset to use in your 
assignments.

- Make sure the data you choose can support both linear and logistic regression.

**Please do not forget to complete 
[`R` Exercise 1](wk1/exercise/exercise1.html) before the workgroup meeting!**

### Useful Information and Links

These links point to useful references that connect to this week's material. 

- [The tidyverse style guide](https://style.tidyverse.org)
- [R for Data Science](https://r4ds.had.co.nz): A great book that details a 
useful toolset for current and aspiring data scientists.

## Column 2

### `R` Exercise

This week's `R` exercise comes in three parts. We need to cover a lot of ground 
this week to get you ready for the rest of the course.

- Complete [Exercise 1](wk1/exercise/exercise1.html) before Thursday's workgroup 
meeting. This exercise will get you started with `R` and `RStudio`.

- Complete [Exercise 2](wk1/exercise/exercise2.html) during Thursday's workgroup 
meeting. 

- Complete and submit [Exercise 3](wk1/exercise/exercise3.html) before the next 
lecture. For this week, you only need to present the `R` code for the relevant 
exercises.

Submit an `R` script containing your answers to Exercise 3 to the 
[SurfDrive][sd] drop folder. Name the file `your_name_3.R`. Where `your_name` is 
your full name in *lower snake case*, and the `3` indicates Exercise 3.

- E.g., My name is Kyle Lang, so my submission would be called `kyle_lang_3.R`.
- Submit these files ***before the next lecture***. 

### Exercise Solutions

You can find suggested solutions to the exercises below. We provide these 
solutions files for two reasons:

1. So you won't ever get intractably stuck on a question
1. So you can check your answers after you attempt a problem.

Even though you have the solutions available, we strongly encourage you to 
seriously attempt answering each question in the exercises before checking the 
solutions. 

1. [Exercise 1](wk1/exercise/exercise1_solutions.html)
1. [Exercise 2](wk1/exercise/exercise2_solutions.html)
1. [Exercise 3](wk1/exercise/exercise3_solutions.html)

<!--
### Exercise Discussion
The video discussions for the practical exercises:

- [Exercise 1 discussion](https://www.dropbox.com/s/qgxlrrl808klmjq/Exercise1_discussion.mp4?dl=0)
- [Exercise 2 discussion](https://www.dropbox.com/s/7bxqj6gn7occ0yr/Exercise%202_discussion.mp4?dl=0)
- [Exercise 3 discussion](https://www.dropbox.com/s/dl5jklj4oixfpxd/Exercise3_discussion.mp4?dl=0)
-->

<!----------------------------------------------------------------------------->

# Week 2

## Column 1

### Lecture (Monday)

Today's lecture has three parts:

1. Data Manipulation: We'll explore various ways of subsetting and manipulating 
your data using base-R functions and routines from the **dplyr** package.
1. Pipes: We'll cover the *pipe* operator and show how you can use *pipelines* 
to more efficiently organize your `R` code.
1. Squared Deviations: We'll discuss *squared deviations* and explore how they 
are used in statistics.

You can find the lecture slides [here](wk2/lecture/lecture2.html)

#### Videos

Below, you can find a recording of the residual lecture content that we were not 
able to cover in the live lecture.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/f-viabUVPnY" 
        title="Squared Deviations" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In today's workgroup, you will get approval for the dataset that you located 
last week and begin processing, cleaning, and exploring the data. You will also 
formulate a research hypothesis for Assignment 1.

## Column 2

### `R` Exercise

This week's `R` exercise is about getting familiar with pipes and basic data 
manipulations.

- Complete [Exercise 4](wk2/exercise/exercise4.html) before Thursday's workgroup.

Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_4.Rmd` and `your_name_4.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`4` indicates Exercise 4. 

- Submit these files ***before the next lecture***.  

### Exercise Solutions

You can find the suggested solutions for Exercise 4 [here](wk2/exercise/exercise4_solutions.html)

### Useful References

The following links point to  useful references that connect with this week's 
material.

- [`magrittr`](https://magrittr.tidyverse.org)
- [`R` for Data Science](http://r4ds.had.co.nz) 
   - [Chapter 18: Pipes](http://r4ds.had.co.nz/pipes.html)

<!----------------------------------------------------------------------------->

# Week 3

## Column 1

### Lecture (Monday)

Today's lecture comes in two parts:

1. Introduction to the *Linear Model*: Linear modeling is the ubiquitous 
workhorse of statistics and data science. In this lecture, we'll go over the 
basics of linear modeling. Next time, we'll dive deeper into the linear model 
and its assumptions.
   - You can find the slides on linear modeling [here](wk3/lecture/linearModel.pdf)
   - Below, I have embedded the recording of the residual lecture content that 
   we were not able to cover during the in-person lecture.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/5QP4tuUmrgA" 
        title="Multiple Linear Regression" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

2. Data Visualization with **ggplot2**: The **ggplot2** package is one of the 
most popular (and rightly so) data visualization tools. In this lecture, you'll 
get an introduction to the process of making visual sense of your data using the 
routines provided by **ggplot2**.
   - There is already a glut of excellent introductions to ggplot available 
   online. So, rather than re-inventing the wheel, we will refer you to the 
   following tutorial video for the ggplot introduction portion of this lecture. 

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/N5gYo43oLE8" 
        title="GGPlot Tutorial" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In today's workgroup, you will work on specifying a linear model and estimating 
your defined model.

## Column 2

### `R` exercise

This week's `R` exercise is about simple linear modeling a visualizing bivariate 
relations.

- Complete [Exercise 5](wk3/exercise/exercise5.html) before Thursday's workgroup.

Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_5.Rmd` and `your_name_5.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`5` indicates Exercise 5. 

- Submit these files ***before the next lecture***.

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk3/exercise/exercise5_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 3: Linear Regression (Section 3.1)
   - Chapter 6: Linear Model Selection and Regularization (Section 6.1)
- [This blog post](https://thestatsgeek.com/2014/01/25/r-squared-and-goodness-of-fit-in-linear-regression/) 
by Jonathan Barlett discussing the $R^2$ and how it cannot tell us if our model 
is misspecified
- [This blog post](https://thestatsgeek.com/2013/10/28/r-squared-and-adjusted-r-squared/) 
 by Jonathan discussing the differences between the $R^2$ and the adjusted $R^2$
- [These lecture notes](http://www.mit.edu/~6.s085/notes/lecture3.pdf) cover the essence of Weeks 3, 4, and 5.

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 4

## Column 1

### Lecture (Monday)
Today's lecture also comes in two parts:

1. Extensions to the linear model: This week, we will complicate the right hand 
side of the regression equation by including categorical predictor variables and 
interaction terms.
   - You can find the slides on complicating the RHS [here](wk4/lecture/rhs.pdf)
   - This part of the lecture has been pre-recorded. You can find the recordings
   below.
   
<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/D40futJ7lkA" 
        title="Categorical Predictors" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/WeYrA3pQhAU" 
        title="Moderation" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/u2KxhHKNqR8" 
        title="Polynomial Regression" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

2. Assumptions, diagnostics, and influential cases: The estimates we get from a 
linear model are only valid when the assumptions underlying that model hold. In 
this lecture, we'll go over the assumptions of linear regression and some 
diagnostic tools you can use to check the assumptions. We will also discuss 
influential cases and how to detect and treat them.
   - You can find the slides on assumptions and diagnostics [here](wk4/lecture/assumptions.pdf)
   - We will do this part of the lecture live on Monday.
   - You can access the recording of the residual lecture content (on 
   influential observations) below.
 
<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/509LwIgzzUo" 
        title="Influential Observations" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>
   
### Workgroup (Thursday)

In today's workgroup, you will check the assumptions of your model and use your
estimated model to test your research hypotheses.

## Column 2

### `R` exercise

This week's `R` exercise is about checking the assumptions of the linear model.

- Complete [Exercise 6](wk4/exercise/exercise6.html) before Thursday's workgroup.

Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_6.Rmd` and `your_name_6.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`6` indicates Exercise 6. 

- Submit these files ***before the next lecture***.

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk4/exercise/exercise6_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 3: Linear Regression (Sections 3.2 -- 3.4)

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 5

## Column 1

### Lecture (Monday)

In this week's lecture, we'll wrap up our discussion of linear modeling by 
diving deeper into the three interrelated topics of model-building, prediction, 
and cross-validation.
   
- You can find the lecture slides [here](wk5/lecture/prediction.pdf)
- You can access the recorded residual lecture content (on cross-validation) below:

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/ot3TtPccnq4" 
        title="Cross-Validation" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<!--
1. Statistical Modeling: In the second part of our lecture, we'll take a more 
nuanced look at the idea of *statistical modeling* and discuss the two modeling 
traditions described by [Breiman (2001)](https://doi.org/10.1214/ss/1009213726).
   - You can find the lecture slides for Part 2 [here](wk5/lecture/modeling.pdf)
   - Part 2 of this week's lecture will be pre-recorded.

<div align = "center">
***I will embed the video here***
</div>
-->

### Workgroup (Thursday)

In this week's workgroup, you will work on finalizing the analysis for 
Assignment 1.

## Column 2

### `R` exercise

This week's `R` exercise will guide you through a complete analysis using linear 
regression.

- [Exercise 7](wk5/exercise/exercise7.html). 

**We want you to focus on finishing Assignment 1, this week. So, you do not need 
to submit Exercise 7.**

- Make sure you understand the exercise and can implement all of the techniques 
covered therein.
- The exercises are exam material, so the content of Exercise 7 may come up in 
the exam.

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk5/exercise/exercise7_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 5: Resampling Methods (Section 5.1)
- [This annotated document](wk5/literature/Example_CVlm.pdf) prepared by Gerko 
Vink explaining some example output from the `CVlm()` function.

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 6

## Column 1

### Lecture (Monday)

In this week's lecture, we will discuss the generalized linear model and begin 
our coverage of logistic regression. 

- You can find the lecture slides [here](wk6/lecture/glm.pdf)
- You can find the recording of the residual lecture content below.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/A6naNS9YIrs" 
        title="Classification Performance" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In this week's workgroup, you will start working on Assignment 2. 

- Although the winter break is right around the corner, we strongly encourage 
you to attend the workgroup this week. If you miss the information presented in 
this week's workgroup, you're likely to fall behind on your second assignment 
during the break.

## Column 2

### `R` exercise

This week's `R` exercise is about fitting logistic regression models. 

- You can find Exercise 8 [here](wk6/exercise/exercise8.html). 

**To help you relax over the break, we won't ask you to submit anything for 
Exercise 8. Make sure you understand what's happening in the exercise, though.**

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk6/exercise/exercise8_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 4: Classification (Up to, and including, Section 4.3.4)

- [This webpage](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/)
discussing how to interpret the estimates from a logistic regression

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 7

## Column 1

### Lecture (Monday)

In this week's lecture, we will continue with logistic regression. We'll use the 
Titanic data to demonstrate a more complete analysis. We will also discuss 
estimation, model evaluation, assumptions, and diagnostics for logistic 
regression models.

- You can find the lecture slides [here](wk7/lecture/lecture7.html)
- You can find the residual lecture recordings below.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/mGvL1ldLZt0" 
        title="Logistic Regression Assumptions" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/xMGpABgq3OQ" 
        title="Classification & Visualization" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In this week's workgroup, you will continue to work on Assignment 2. You should 
evaluate the model you defined in the last workgroup and use this model to test
your hypotheses.

## Column 2

### `R` exercise

For this week's exercise, you will use the [titanic.rds data](data/titanic.rds)
to complete the following tasks.

1. Randomly split the data into a training set of $N = 800$ observations and a 
testing set of $N = 87$ observations.
2. Recreate the plots from Slides 47 and 48 with two alterations:
   a. Plot only the results for males.
   a. Use the testing data to generate the plots.
3. Use the additive model estimated on Slide 20 to do the following:
   a. Create a confusion matrix from the training data.
   a. Create a confusion matrix from the testing data.
   a. Compute the Sensitivity, Specificity, and Accuracy from the training data.
   a. Compute the True Positive Rate, The True Negative Rate, and the Error Rate 
   from the testing data. 
4. Estimate a model wherein survival probability is predicted by all other 
variables in the dataset except for `name`. 
   - Use the different methods of model evaulation discussed in the lecture 
   (including cross-validation) to test if this model fits/predicts better than 
   the moderated model estimated on Slide 21.
   
Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_9.Rmd` and `your_name_9.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`9` indicates Exercise 9. 

- Submit these files ***before the next lecture***.

### Required Reading

- [This webpage](https://stats.idre.ucla.edu/r/dae/logit-regression/) walking 
through an example analysis using logistic regression

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 8

## Column 1

### Lecture (Monday)

In this week's lecture, we will wrap up the course. I'll give an overview of the 
main points we've covered. 

- You can find the lecture slides [here](wk8/summary.pdf)

### Workgroup (Thursday)

In these week's workgroup, you will finalize your second group project.

## Column 2

### `R` exercise
There is no R exercise this week. Use your time to finish the second assignment 
and prepare for the exam. 

<!----------------------------------------------------------------------------->

# Exam Material

## Column 1

### **Practice Exam**

You can find the practice exam [here](https://kylelang.shinyapps.io/practice_exam)

### **What can be tested?**

Anything mentioned in the lectures may appear on the exam. This includes both 
information printed in the lecture slides and information delivered verbally 
during a lecture itself.

- Although the readings should be helpful for learning/reinforcing the concepts 
covered in the lectures, we will not test you on any concept that appears in 
a reading but was not addressed in the lectures.

### **What about equations?**

This is not a math class; we are not trying to test your ability to do 
calculations or manipulate equations. That being said, a certain degree of 
mathematical literacy is crucial to statistics and data science, so you will 
have to do some simple calculations on the exam. For example, you should be 
comfortable with the following.

- Working with the linear regression equation, $Y_i = \beta_0 + \beta_1 X_i +\varepsilon_i$, to:
   - Calculate predicted values give certain inputs
   - Interpret parameter estimates
   - Evaluate hypotheses/research questions

- The differences between:
   - The full regression model: $Y_i = \hat{\beta}_0 + \hat{\beta}_1 X_i +\hat{\varepsilon}_i$
   - The equation for the best-fit line: $\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i$

- The definition of a residual: 
   - $\hat{\varepsilon}_i = Y_i - \hat{Y}_i$

- The relationship between probabilities ($p$) and odds (for binary outcomes):
   - $\text{odds} = \frac{p}{1-p}$

- The definition of the logit function:
   - $\log(\text{odds}) = \log\left(\frac{p}{1-p}\right) = \text{logit}(p)$

- The definition of the logistic function, its relation to the logit function, 
and its role in logistic regression:
   - $\text{logistic}(\eta_i) = \text{logit}^{-1}(p_i) = \frac{\exp(\eta_i)}{1+\exp(\eta_i)} = \frac{\exp(\hat{\beta}_0 + \hat{\beta}_1 X_i)}{1 + \exp(\hat{\beta}_0 + \hat{\beta}_1 X_i)} = \hat{p}_i$

Of course, you should also be able to do basic arithmetic operations that are 
too trivial to detail here (e.g., calculating the difference between the $R^2$ 
statistics from two models that you are trying to compare).

**Note**: Although all examples above are shown in terms of simple linear 
regression models, you should also be able to do these calculations/interpretations 
using multiple linear regression models and models that include dummy codes, 
interactions, or polynomial terms.

### **What if you're still unsure?**

If any of the course materials confuse you, feel free to ask about it during the 
lecture or one of the weekly Q&A sessions (even if your concerns relate to 
content from earlier weeks). 

**We will devote part (most?) of the final lecture to a dedicated Q&A session**

<!----------------------------------------------------------------------------->

[ftds]: https://osiris.uu.nl/osiris_student_uuprd/OnderwijsCatalogusSelect.do?selectie=cursus&cursus=201900026&collegejaar=2021&taal=en
[sd]: https://surfdrive.surf.nl/files/index.php/s/IQ517X5UitVOayk
[isl]: https://web.stanford.edu/~hastie/ISLR2/ISLRv2_website.pdf
