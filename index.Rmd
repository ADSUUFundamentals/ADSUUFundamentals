---
title: "Fundamental Techniques"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
---

# Intro {.sidebar data-width=300}

This dashboard covers the course materials for the course 
[***Fundamental Techniques in Data Science with R***][ftds]

---

Course Coordinator: [Laura Boeschoten](https://www.uu.nl/medewerkers/LBoeschoten) <br>
Lecture Instructor: [Kyle Lang](https://www.kylemlang.com) <br>
WG Instructor: [Laura Boeschoten](https://www.uu.nl/medewerkers/LBoeschoten) <br>
WG Instructor: [Rianne Kraakman](https://www.uu.nl/staff/AMKraakman) <br>
WG Instructor: [Anastasia Giachanou](http://www.giachanou.com/) <br>
Study load: 7.5 ECTS <br>
Assessment: Assignments and Exam <br>
[Course SurfDrive folder][sd]

---

| What?   | When?               | Where?                  |
|---------|---------------------|-------------------------|
|         |                     |                         |
| Lecture | 2021-11-15<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-11-18<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-11-18<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-11-18<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-11-22<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-11-25<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-11-25<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-11-25<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-11-29<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-02<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-02<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-02<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-12-06<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-09<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-09<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-09<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-12-13<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-16<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-16<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-16<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-12-20<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-12-23<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-12-23<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-12-23<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-01-10<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-01-13<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-01-13<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-01-13<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Lecture | 2021-01-17<br>17:15 | Ruppert<br>Blauw        |
| WG1     | 2021-01-20<br>09:00 | Ruppert<br>011          |
| WG3     | 2021-01-20<br>09:00 | Androclus<br>C023       |
| WG2     | 2021-01-20<br>11:00 | Ruppert<br>011          |
|         |                     |                         |
| Exam    | 2021-01-26<br>19:00 | Educatorium<br>Theatron |

---

# Quick Overview

## Column 1 {data-width=400}

### 

In nine weeks, you will learn the basics of data handling with R and details 
about regression techniques in the context of statistical inference. We will 
also cover the connection between these concepts and research philosophy. During 
every lecture, we will cover a different theoretical topic. In addition to the 
lectures, there will also be a weekly computer lab exercise that connects the 
statistical theory to practice. You will also attend weekly workgroup meetings 
wherein you will work on solving motivating, real-world case studies. 

### Assignment and Grading

The final grade is computed as follows

| Grade Component | Weight |
|:-------|:------|
| Linear Regression Assignment | 25% |
| Logistic Regression Assignment | 25% |
| Written Exam | 50% |

In addition to the grade components listed above, you will also do `R` exercises 
for the first 7 weeks of the course. These exercises will develop the skills 
needed to successfully complete the assignments. 

To pass the course:

1. Your final exam grade must be 5.5 or higher
1. Both of your assignments grades must be 5.5 or higher

## Column 2 {data-width=400}

### Schedule

| Week # | Topic | `R` Exercise | Workgroup | Reading |
|-|---|----|----|--|
| 1 | The basics of `R` | How to work with `R` scripts, `R` projects, `R` markdown and how to import external data into `R` | Search for a dataset for the two group assignments | R4DS [Chapter 4](Workflow basics https://r4ds.had.co.nz/workflow-basics.html), [Chapter 6](https://r4ds.had.co.nz/workflow-scripts.html), [Chapter 8](https://r4ds.had.co.nz/workflow-projects.html), [Chapter 11](https://r4ds.had.co.nz/data-import.html) and [Chapter 27](https://r4ds.had.co.nz/r-markdown.html).|
| 2 | Data manipulation in `R`| Data types and objects in `R`, data transformation, working with pipes | Perform data transformations on your found dataset to prepare it for the group assignments | R4DS [Chapter 5](https://r4ds.had.co.nz/transform.html), [Chapter 10](https://r4ds.had.co.nz/tibbles.html), [Chapter 14 (only 14.1 and 14.2)](https://r4ds.had.co.nz/strings.html), [Chapter 15](https://r4ds.had.co.nz/factors.html) and [Chapter 18](https://r4ds.had.co.nz/pipes.html) | 
| 3 | Exploratory data analysis with `R` | Data visualization, data inspection, data cleaning and writing functions in `R` | **Hand in an `R` Markdown with your found data, descriptive statistics and potential transformations before the meeting** Form groups, pitch your found data to your group, continue with data inspection and cleaning for the two assignments | R4DS [Chapter 3](https://r4ds.had.co.nz/data-visualisation.html), [Chapter 7](https://r4ds.had.co.nz/exploratory-data-analysis.html) and [Chapter 19](Functions https://r4ds.had.co.nz/functions.html) | 
| 3 | Linear model 1; Data visualization | The `lm()` function in `R`; Visualizing bivariate relations | Specify a linear model; Fit your defined model | [ISL][isl] 3.1 & 6.1, [Blog Post 1](https://thestatsgeek.com/2014/01/25/r-squared-and-goodness-of-fit-in-linear-regression/), [Blog Post 2](https://thestatsgeek.com/2013/10/28/r-squared-and-adjusted-r-squared/), [Lecture Notes](http://www.mit.edu/~6.s085/notes/lecture3.pdf) |
| 4 | Linear model 2; Assumptions; Diagnostics | Investigating the assumptions of the linear model | Check the assumptions of your model; Use your model to test your hypotheses; Continue the project in `rmarkdown` | [ISL][isl] 3.2 -- 3.4 |
| 5 | Model building; Prediction; Cross-validation | Tying the analytic pieces together into a full regression analysis | Evaluate and, if possible, improve your model; **Prepare Assignment 1; Evaluate the final linear model on your own data** | [ISL][isl] 5.1, [Document](wk5/literature/Example_CVlm.pdf) |
| 6 | Generalized linear model; Logistic regression 1 | The `glm()` function in `R`; Logistic regression modeling; Classification | Formulate a research hypothesis and define a logistic model; Fit your defined model | [ISL][isl] 4.1 -- 4.3 (except 4.3.5), [Webpage](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/) |
| 7 | Logistic regression 2 | Finish exercise from last week | Check the assumptions of your model; Use your model to test your hypotheses | [Webpage](https://stats.idre.ucla.edu/r/dae/logit-regression/)
| 8 | Summary, catch-up, and questions | None | Evaluate and, if possible, improve your model; **Prepare Assignment 2; Evaluate the final logistic model on your own data** |

<!----------------------------------------------------------------------------->

# Course Manual

## Column 1

### Course Content

Regression techniques are widely used to quantify the relationship between two 
or more variables. In data science, linear and logistic regression are common 
and powerful techniques for evaluating such relations. These techniques are only 
useful, however, once you understand when and how to apply them. In this course, 
students will learn how to apply linear and logistic regression with the `R` 
statistical software package.
 
This course will introduce students to the principles of analytical data science, 
linear and logistic regression, and the basics of statistical learning. Students
will develop fundamental `R` programming skills and will gain experience with 
tidyverse: visualize data with ggplot2 and performing basic data wrangling with 
dplyr. This course helps prepare students for an entry-level research career 
(e.g. junior researcher or research assistant) or further education in research 
(e.g., a [research] Master program or a PhD).


### Course goals

At the end of this course, students are able to:

1.  Identify key statistical concepts such as:
    *	(Conditional) probability
    *	Inference
    * Estimation
    *	Prediction
    *	Classification
    *	Sampling variability
    *	Statistical modeling
    *	Residuals
    *	Fitted values
2.  Choose an appropriate regression model for a given research scenario.
3.	Explain the differences/similarities between statistical inference and model-based prediction/classification; give examples of each type of problem.
4.	Identify the assumptions of linear and logistic regression; describe the consequences of violating these assumptions.
5.	Describe the three components of a generalized linear model and how these components are specified in logistic regression.
6.	Interpret the estimates from linear and logistic regression models, and use these estimates to answer research questions.
7.	Use the `R` statistical software platform to perform basic statistical programming, data manipulation, data visualization, and basic data wrangling.
8.	Use the `R` statistical software platform to perform, interpret, and evaluate linear and logistic regression analyses on real-world data.
9.	Interpret `R` output and use the results to answer research questions.
10.	Use `R` Markdown to document the results of a statistical analysis.

### Relation between assessment and objective 

In this course, skills and knowledge are evaluated with two types of assignment.

1.    The exam evaluates knowledge and understanding of statistical concepts (learning goal 1), the ability to critically evaluate research problems and statistical methods (learning goals 2–5), and the ability to interpret statistical results and software output and apply these interpretations (learning goals 6 & 9).
2.    The group assignments evaluate the student’s ability to work with data, solve basic data analytic problems, execute quantitative data analyses on real-world data sets, and document the results (learning goals 6–10).

### Course structure 

In eight weeks, you will learn the basics of data handling and statistical programming with R and details about regression techniques in the context of statistical inference, prediction, and classification. Each week will comprise three class activities:

1.    During the weekly lectures, we will cover the theoretical content.
2.    Weekly practical exercises connect the statistical theory to practice by applying the lecture content in the R statistical programming language.
3.    During the weekly workgroup meetings, you will work on real-world data analysis with a group of your peers.




<!----------------------------------------------------------------------------->

# Preparation

## Column 1

###

Hello All, 

This semester, you will participate in the **Fundamental Techniques in Data 
Science with `R`** course at Utrecht University. In this course, you will use 
both `R` and `RStudio`. The below steps guide you through installing both `R` 
and `RStudio`. Please do so before the first meeting. 

Regards,  
Instructor Team

### **System requirements**

Bring a laptop computer to the course and make sure that you have full write 
access and administrator rights on the machine. We will explore programming and 
compiling in this course, so you will need full access to your machine. Some 
corporate laptops come with limited access for their users, I therefore advise 
you to bring a personal laptop to the workgroup meetings. 

### **1. Install `R`**

You can obtain a copy of `R` [here](https://cran.r-project.org). We won't use 
`R` directly in the course. Rather, we'll call `R` through `RStudio`. Therefore, 
you also need to install `RStudio`. 

### **2. Install `RStudio` Desktop**

`RStudio` is an Integrated Development Environment (IDE) for `R`. You can 
download `RStudio` as stand-alone software [here](https://www.rstudio.com/products/rstudio/download/#download). 
The free and open-source `RStudio Desktop` version is sufficient.

### **3. Start RStudio and install the following packages. **

Open `RStudio`, and copy-paste the following lines of code into the console 
window to execute them.

- If nothing happens after you paste the code, try hitting the "Enter/Return" 
key.

```{r eval = FALSE, echo = TRUE}
install.packages(c("ggplot2", 
                   "tidyverse", 
                   "magrittr", 
                   "micemd", 
                   "jomo", 
                   "pan", 
                   "lme4", 
                   "knitr", 
                   "rmarkdown", 
                   "plotly", 
                   "ggplot2", 
                   "shiny", 
                   "devtools", 
                   "boot", 
                   "class", 
                   "car", 
                   "MASS", 
                   "ggplot2movies", 
                   "ISLR", 
                   "DAAG", 
                   "mice"), 
                 dependencies = TRUE)
```

If you are not sure where to paste the code, use the following figure to 
identify the console:

<center>
  <img src="images/console.png" alt="HTML5 Icon" width = 70%>
</center>

When you are asked the following:

```{r eval = FALSE, echo = TRUE}
Do you want to install from sources the package which needs 
compilation? (Yes/no/cancel)
```

Type `Yes` in the console, and press the "Enter/Return" key (or click the 
corresponding button if the question presents as a dialog box). 

### **What if the steps to the left do not work for me?**

If the suggested steps fail or you have insufficient rights on your machine, you 
can use the following web-based solutions. 

1. Open a free account on [rstudio.cloud](https://rstudio.cloud). 

   - You can run your own cloud-based `RStudio` environment there.
   
<br>

2. Use Utrecht University's [MyWorkPlace](https://myworkplace.uu.nl/). 

   - You will have access to `R` and `RStudio` there. When you start a new 
   MyWorkPlace session, you may need to (re)install packages. 

Naturally, you will need internet access to use these services. 

## Column 2

### Necessary background knowledge

We expect you to be familiar with basic statistical concepts such as:

*   Descriptive statistics
*   Sampling
*   Correlation
*   T-test
*   P-values 

In order to refresh your memory you can have a look at the material below. Note 
that we consider this background knowledge for this course and known by all of
you. The course material for this course further builds on this knowledge, so
therefore this is not exam material itself. 

### Descriptive statistics 

Play around with [this shiny app](https://utrecht-university.shinyapps.io/Descriptives/).

### Sampling 

Play around with [this shiny app](https://utrecht-university.shinyapps.io/sampling/).

### Correlation

Play around with these shiny apps ([on correlation](https://utrecht-university.shinyapps.io/correlation/) 
and on [correlation and sampling](https://utrecht-university.shinyapps.io/samplingcorrelations/)).

### T-test

Play around with [this shiny app](https://utrecht-university.shinyapps.io/t_test/).

### P-values

Play around with [this shiny app](https://utrecht-university.shinyapps.io/Randomization_p-values/).

<!----------------------------------------------------------------------------->

# Week 1

## Column 1

### Lecture (Monday)

Today's lecture is about the elemental building blocks of `R`. We will discuss 
what `R` actually is, why we use `RStudio`, how to 'speak' `R`, and how to work 
with `R` objects. 

You can find the lecture slides [here](wk1/lecture/lecture1.html)

#### Videos

Below, you can find recordings of the residual lecture content that we were not 
able to cover in the live lecture.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/xhPNgtj8eBY" 
        title="Lecture 1 Extra (Part 1)" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>
        
<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/XjoTxUp6YxE" 
        title="Lecture 1 Extra (Part 1)" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)
        
You should attend all workgroup meetings; however, **today's meeting is vital**! 
We will form groups, and we will discuss the assignments and expectations for 
your work in this course. You will also locate a dataset to use in your 
assignments.

- Make sure the data you choose can support both linear and logistic regression.

**Please do not forget to complete 
[`R` Exercise 1](wk1/exercise/exercise1.html) before the workgroup meeting!**

### Useful Information and Links

These links point to useful references that connect to this week's material. 

- [The tidyverse style guide](https://style.tidyverse.org)
- [R for Data Science](https://r4ds.had.co.nz): A great book that details a 
useful toolset for current and aspiring data scientists.

## Column 2

### `R` Exercise

This week's `R` exercise comes in three parts. We need to cover a lot of ground 
this week to get you ready for the rest of the course.

- Complete [Exercise 1](wk1/exercise/exercise1.html) before Thursday's workgroup 
meeting. This exercise will get you started with `R` and `RStudio`.

- Complete [Exercise 2](wk1/exercise/exercise2.html) during Thursday's workgroup 
meeting. 

- Complete and submit [Exercise 3](wk1/exercise/exercise3.html) before the next 
lecture. For this week, you only need to present the `R` code for the relevant 
exercises.

Submit an `R` script containing your answers to Exercise 3 to the 
[SurfDrive][sd] drop folder. Name the file `your_name_3.R`. Where `your_name` is 
your full name in *lower snake case*, and the `3` indicates Exercise 3.

- E.g., My name is Kyle Lang, so my submission would be called `kyle_lang_3.R`.
- Submit these files ***before the next lecture***. 

### Exercise Solutions

You can find suggested solutions to the exercises below. We provide these 
solutions files for two reasons:

1. So you won't ever get intractably stuck on a question
1. So you can check your answers after you attempt a problem.

Even though you have the solutions available, we strongly encourage you to 
seriously attempt answering each question in the exercises before checking the 
solutions. 

1. [Exercise 1](wk1/exercise/exercise1_solutions.html)
1. [Exercise 2](wk1/exercise/exercise2_solutions.html)
1. [Exercise 3](wk1/exercise/exercise3_solutions.html)

<!--
### Exercise Discussion
The video discussions for the practical exercises:

- [Exercise 1 discussion](https://www.dropbox.com/s/qgxlrrl808klmjq/Exercise1_discussion.mp4?dl=0)
- [Exercise 2 discussion](https://www.dropbox.com/s/7bxqj6gn7occ0yr/Exercise%202_discussion.mp4?dl=0)
- [Exercise 3 discussion](https://www.dropbox.com/s/dl5jklj4oixfpxd/Exercise3_discussion.mp4?dl=0)
-->

<!----------------------------------------------------------------------------->

# Week 2

## Column 1

### Lecture (Monday)

Today's lecture has three parts:

1. Data Manipulation: We'll explore various ways of subsetting and manipulating 
your data using base-R functions and routines from the **dplyr** package.
1. Pipes: We'll cover the *pipe* operator and show how you can use *pipelines* 
to more efficiently organize your `R` code.
1. Squared Deviations: We'll discuss *squared deviations* and explore how they 
are used in statistics.

You can find the lecture slides [here](wk2/lecture/lecture2.html)

#### Videos

Below, you can find a recording of the residual lecture content that we were not 
able to cover in the live lecture.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/f-viabUVPnY" 
        title="Squared Deviations" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In today's workgroup, you will get approval for the dataset that you located 
last week and begin processing, cleaning, and exploring the data. You will also 
formulate a research hypothesis for Assignment 1.

## Column 2

### `R` Exercise

This week's `R` exercise is about getting familiar with pipes and basic data 
manipulations.

- Complete [Exercise 4](wk2/exercise/exercise4.html) before Thursday's workgroup.

Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_4.Rmd` and `your_name_4.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`4` indicates Exercise 4. 

- Submit these files ***before the next lecture***.  

### Exercise Solutions

You can find the suggested solutions for Exercise 4 [here](wk2/exercise/exercise4_solutions.html)

### Useful References

The following links point to  useful references that connect with this week's 
material.

- [`magrittr`](https://magrittr.tidyverse.org)
- [`R` for Data Science](http://r4ds.had.co.nz) 
   - [Chapter 18: Pipes](http://r4ds.had.co.nz/pipes.html)

<!----------------------------------------------------------------------------->

# Week 3

## Column 1

### Lecture (Monday)

Today's lecture comes in two parts:

1. Introduction to the *Linear Model*: Linear modeling is the ubiquitous 
workhorse of statistics and data science. In this lecture, we'll go over the 
basics of linear modeling. Next time, we'll dive deeper into the linear model 
and its assumptions.
   - You can find the slides on linear modeling [here](wk3/lecture/linearModel.pdf)
   - Below, I have embedded the recording of the residual lecture content that 
   we were not able to cover during the in-person lecture.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/5QP4tuUmrgA" 
        title="Multiple Linear Regression" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

2. Data Visualization with **ggplot2**: The **ggplot2** package is one of the 
most popular (and rightly so) data visualization tools. In this lecture, you'll 
get an introduction to the process of making visual sense of your data using the 
routines provided by **ggplot2**.
   - There is already a glut of excellent introductions to ggplot available 
   online. So, rather than re-inventing the wheel, we will refer you to the 
   following tutorial video for the ggplot introduction portion of this lecture. 

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/N5gYo43oLE8" 
        title="GGPlot Tutorial" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In today's workgroup, you will work on specifying a linear model and estimating 
your defined model.

## Column 2

### `R` exercise

This week's `R` exercise is about simple linear modeling a visualizing bivariate 
relations.

- Complete [Exercise 5](wk3/exercise/exercise5.html) before Thursday's workgroup.

Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_5.Rmd` and `your_name_5.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`5` indicates Exercise 5. 

- Submit these files ***before the next lecture***.

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk3/exercise/exercise5_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 3: Linear Regression (Section 3.1)
   - Chapter 6: Linear Model Selection and Regularization (Section 6.1)
- [This blog post](https://thestatsgeek.com/2014/01/25/r-squared-and-goodness-of-fit-in-linear-regression/) 
by Jonathan Barlett discussing the $R^2$ and how it cannot tell us if our model 
is misspecified
- [This blog post](https://thestatsgeek.com/2013/10/28/r-squared-and-adjusted-r-squared/) 
 by Jonathan discussing the differences between the $R^2$ and the adjusted $R^2$
- [These lecture notes](http://www.mit.edu/~6.s085/notes/lecture3.pdf) cover the essence of Weeks 3, 4, and 5.

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 4

## Column 1

### Lecture (Monday)
Today's lecture also comes in two parts:

1. Extensions to the linear model: This week, we will complicate the right hand 
side of the regression equation by including categorical predictor variables and 
interaction terms.
   - You can find the slides on complicating the RHS [here](wk4/lecture/rhs.pdf)
   - This part of the lecture has been pre-recorded. You can find the recordings
   below.
   
<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/D40futJ7lkA" 
        title="Categorical Predictors" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/WeYrA3pQhAU" 
        title="Moderation" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/u2KxhHKNqR8" 
        title="Polynomial Regression" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

2. Assumptions, diagnostics, and influential cases: The estimates we get from a 
linear model are only valid when the assumptions underlying that model hold. In 
this lecture, we'll go over the assumptions of linear regression and some 
diagnostic tools you can use to check the assumptions. We will also discuss 
influential cases and how to detect and treat them.
   - You can find the slides on assumptions and diagnostics [here](wk4/lecture/assumptions.pdf)
   - We will do this part of the lecture live on Monday.
   - You can access the recording of the residual lecture content (on 
   influential observations) below.
 
<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/509LwIgzzUo" 
        title="Influential Observations" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>
   
### Workgroup (Thursday)

In today's workgroup, you will check the assumptions of your model and use your
estimated model to test your research hypotheses.

## Column 2

### `R` exercise

This week's `R` exercise is about checking the assumptions of the linear model.

- Complete [Exercise 6](wk4/exercise/exercise6.html) before Thursday's workgroup.

Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_6.Rmd` and `your_name_6.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`6` indicates Exercise 6. 

- Submit these files ***before the next lecture***.

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk4/exercise/exercise6_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 3: Linear Regression (Sections 3.2 -- 3.4)

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 5

## Column 1

### Lecture (Monday)

In this week's lecture, we'll wrap up our discussion of linear modeling by 
diving deeper into the three interrelated topics of model-building, prediction, 
and cross-validation.
   
- You can find the lecture slides [here](wk5/lecture/prediction.pdf)
- You can access the recorded residual lecture content (on cross-validation) below:

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/ot3TtPccnq4" 
        title="Cross-Validation" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<!--
1. Statistical Modeling: In the second part of our lecture, we'll take a more 
nuanced look at the idea of *statistical modeling* and discuss the two modeling 
traditions described by [Breiman (2001)](https://doi.org/10.1214/ss/1009213726).
   - You can find the lecture slides for Part 2 [here](wk5/lecture/modeling.pdf)
   - Part 2 of this week's lecture will be pre-recorded.

<div align = "center">
***I will embed the video here***
</div>
-->

### Workgroup (Thursday)

In this week's workgroup, you will work on finalizing the analysis for 
Assignment 1.

## Column 2

### `R` exercise

This week's `R` exercise will guide you through a complete analysis using linear 
regression.

- [Exercise 7](wk5/exercise/exercise7.html). 

**We want you to focus on finishing Assignment 1, this week. So, you do not need 
to submit Exercise 7.**

- Make sure you understand the exercise and can implement all of the techniques 
covered therein.
- The exercises are exam material, so the content of Exercise 7 may come up in 
the exam.

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk5/exercise/exercise7_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 5: Resampling Methods (Section 5.1)
- [This annotated document](wk5/literature/Example_CVlm.pdf) prepared by Gerko 
Vink explaining some example output from the `CVlm()` function.

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 6

## Column 1

### Lecture (Monday)

In this week's lecture, we will discuss the generalized linear model and begin 
our coverage of logistic regression. 

- You can find the lecture slides [here](wk6/lecture/glm.pdf)
- You can find the recording of the residual lecture content below.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/A6naNS9YIrs" 
        title="Classification Performance" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In this week's workgroup, you will start working on Assignment 2. 

- Although the winter break is right around the corner, we strongly encourage 
you to attend the workgroup this week. If you miss the information presented in 
this week's workgroup, you're likely to fall behind on your second assignment 
during the break.

## Column 2

### `R` exercise

This week's `R` exercise is about fitting logistic regression models. 

- You can find Exercise 8 [here](wk6/exercise/exercise8.html). 

**To help you relax over the break, we won't ask you to submit anything for 
Exercise 8. Make sure you understand what's happening in the exercise, though.**

### Exercise Solutions

You can find suggested solutions for this week's exercise [here](wk6/exercise/exercise8_solutions.html).

### Required Reading

- [Introduction to Statistical Learning][isl] 
   - Chapter 4: Classification (Up to, and including, Section 4.3.4)

- [This webpage](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/)
discussing how to interpret the estimates from a logistic regression

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 7

## Column 1

### Lecture (Monday)

In this week's lecture, we will continue with logistic regression. We'll use the 
Titanic data to demonstrate a more complete analysis. We will also discuss 
estimation, model evaluation, assumptions, and diagnostics for logistic 
regression models.

- You can find the lecture slides [here](wk7/lecture/lecture7.html)
- You can find the residual lecture recordings below.

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/mGvL1ldLZt0" 
        title="Logistic Regression Assumptions" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

<iframe width="560" 
        height="315" 
        src="https://www.youtube.com/embed/xMGpABgq3OQ" 
        title="Classification & Visualization" 
        frameborder="0" 
        allow="accelerometer; 
               autoplay; 
               clipboard-write; 
               encrypted-media; 
               gyroscope; 
               picture-in-picture" 
        allowfullscreen
        data-external="1">
</iframe>

### Workgroup (Thursday)

In this week's workgroup, you will continue to work on Assignment 2. You should 
evaluate the model you defined in the last workgroup and use this model to test
your hypotheses.

## Column 2

### `R` exercise

For this week's exercise, you will use the [titanic.rds data](data/titanic.rds)
to complete the following tasks.

1. Randomly split the data into a training set of $N = 800$ observations and a 
testing set of $N = 87$ observations.
2. Recreate the plots from Slides 47 and 48 with two alterations:
   a. Plot only the results for males.
   a. Use the testing data to generate the plots.
3. Use the additive model estimated on Slide 20 to do the following:
   a. Create a confusion matrix from the training data.
   a. Create a confusion matrix from the testing data.
   a. Compute the Sensitivity, Specificity, and Accuracy from the training data.
   a. Compute the True Positive Rate, The True Negative Rate, and the Error Rate 
   from the testing data. 
4. Estimate a model wherein survival probability is predicted by all other 
variables in the dataset except for `name`. 
   - Use the different methods of model evaulation discussed in the lecture 
   (including cross-validation) to test if this model fits/predicts better than 
   the moderated model estimated on Slide 21.
   
Submit your *RMD* script and the compiled *HTML* file it produces to the 
[SurfDrive][sd] folder. Name the files `your_name_9.Rmd` and `your_name_9.html`, 
respectively. Where `your_name` is your full name in *lower snake case*, and the
`9` indicates Exercise 9. 

- Submit these files ***before the next lecture***.

### Required Reading

- [This webpage](https://stats.idre.ucla.edu/r/dae/logit-regression/) walking 
through an example analysis using logistic regression

***These readings are exam materials.***

<!----------------------------------------------------------------------------->

# Week 8

## Column 1

### Lecture (Monday)

In this week's lecture, we will wrap up the course. I'll give an overview of the 
main points we've covered. 

- You can find the lecture slides [here](wk8/summary.pdf)

### Workgroup (Thursday)

In these week's workgroup, you will finalize your second group project.

## Column 2

### `R` exercise
There is no R exercise this week. Use your time to finish the second assignment 
and prepare for the exam. 

<!----------------------------------------------------------------------------->

# Exam Material

## Column 1

### **Practice Exam**

You can find the practice exam [here](https://kylelang.shinyapps.io/practice_exam)

### **What can be tested?**

Anything mentioned in the lectures may appear on the exam. This includes both 
information printed in the lecture slides and information delivered verbally 
during a lecture itself.

- Although the readings should be helpful for learning/reinforcing the concepts 
covered in the lectures, we will not test you on any concept that appears in 
a reading but was not addressed in the lectures.

### **What about equations?**

This is not a math class; we are not trying to test your ability to do 
calculations or manipulate equations. That being said, a certain degree of 
mathematical literacy is crucial to statistics and data science, so you will 
have to do some simple calculations on the exam. For example, you should be 
comfortable with the following.

- Working with the linear regression equation, $Y_i = \beta_0 + \beta_1 X_i +\varepsilon_i$, to:
   - Calculate predicted values give certain inputs
   - Interpret parameter estimates
   - Evaluate hypotheses/research questions

- The differences between:
   - The full regression model: $Y_i = \hat{\beta}_0 + \hat{\beta}_1 X_i +\hat{\varepsilon}_i$
   - The equation for the best-fit line: $\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i$

- The definition of a residual: 
   - $\hat{\varepsilon}_i = Y_i - \hat{Y}_i$

- The relationship between probabilities ($p$) and odds (for binary outcomes):
   - $\text{odds} = \frac{p}{1-p}$

- The definition of the logit function:
   - $\log(\text{odds}) = \log\left(\frac{p}{1-p}\right) = \text{logit}(p)$

- The definition of the logistic function, its relation to the logit function, 
and its role in logistic regression:
   - $\text{logistic}(\eta_i) = \text{logit}^{-1}(p_i) = \frac{\exp(\eta_i)}{1+\exp(\eta_i)} = \frac{\exp(\hat{\beta}_0 + \hat{\beta}_1 X_i)}{1 + \exp(\hat{\beta}_0 + \hat{\beta}_1 X_i)} = \hat{p}_i$

Of course, you should also be able to do basic arithmetic operations that are 
too trivial to detail here (e.g., calculating the difference between the $R^2$ 
statistics from two models that you are trying to compare).

**Note**: Although all examples above are shown in terms of simple linear 
regression models, you should also be able to do these calculations/interpretations 
using multiple linear regression models and models that include dummy codes, 
interactions, or polynomial terms.

### **What if you're still unsure?**

If any of the course materials confuse you, feel free to ask about it during the 
lecture or one of the weekly Q&A sessions (even if your concerns relate to 
content from earlier weeks). 

**We will devote part (most?) of the final lecture to a dedicated Q&A session**

<!----------------------------------------------------------------------------->

[ftds]: https://osiris.uu.nl/osiris_student_uuprd/OnderwijsCatalogusSelect.do?selectie=cursus&cursus=201900026&collegejaar=2021&taal=en
[sd]: https://surfdrive.surf.nl/files/index.php/s/IQ517X5UitVOayk
[isl]: https://web.stanford.edu/~hastie/ISLR2/ISLRv2_website.pdf
