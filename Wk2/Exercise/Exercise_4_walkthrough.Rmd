---
title: "Exercise 4"
author: "Gerko Vink"
date: "Fundamental Techniques in Data Science with R"
output: 
   html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: false
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 18px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 18px;
}
h2 { /* Header 2 */
    font-size: 18px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>



```{r echo=FALSE}
printAnswers <- TRUE
```


---

# Exercises

---

The following packages are required for this practical:
```{r, message=FALSE}
library(dplyr)
library(magrittr)
library(mice)
```
and if you'd like the same results as I have obtained, you can fix the random seed
```{r}
set.seed(123)
```

---

## Exercise 1-5

---

1. **Use a pipe to do the following:**

- draw 1000 values from a normal distribution with `mean = 5` and `sd = 1` - $N(5, 1)$, 
- create a matrix where the first 500 values are the first column and the second 500 values are the second column
- make a scatterplot of these two columns
```{r}
rnorm(1000, 5) %>%
  matrix(ncol = 2) %>%
  plot()
```

---

2. **Use a pipe to calculate the correlation matrix on the `anscombe` data set**

```{r}
anscombe %>%
  cor()
```

---

3. **Now use a pipe to calculate the correlation for the pair (`x4`, `y4`) on the `anscombe` data set**

Using the standard `%>%` pipe:
```{r}
anscombe %>%
  subset(select = c(x4, y4)) %>%
  cor()
```
Alternatively, we can use the `%$%` pipe from package `magrittr` to make this process much more efficient.
```{r}
anscombe %$%
  cor(x4, y4)
```

---

4. **Use a pipe to calculate the correlation between `hgt` and `wgt` in the `boys` data set from package `mice`.**

Because `boys` has missings values for almost all variables, we must first select `wgt` and `hgt` and then omit the rows that have missing values, before we can calculate the correlation. Using the standard `%>%` pipe, this would look like:
```{r}
boys %>%
  subset(select = c("wgt", "hgt")) %>%
  cor(use = "pairwise.complete.obs")
```
which is equivalent to 
```{r}
boys %>%
  subset(select = c("wgt", "hgt")) %>%
  na.omit() %>%
  cor()
```

Alternatively, we can use the `%$%` pipe:
```{r}
boys %$% 
  cor(hgt, wgt, use = "pairwise.complete.obs")
```
The `%$%` pipe *unfolds* the listed dimensions of the `boys` dataset, such that we can refer to them directly. 

---

5. **In the `boys` data set, `hgt` is recorded in centimeters. Use a pipe to transform `hgt` in the `boys` dataset to height in meters and verify the transformation**

Using the standard `%>%` and the `%$%` pipes:
```{r}
boys %>%
  transform(hgt = hgt / 100) %$%
  mean(hgt, na.rm = TRUE)
```

---

## Exercise 6-6

---

6. **Use a pipe to plot the pair (`hgt`, `wgt`) two times: once for `hgt` in meters and once for `hgt` in centimeters. Make the points in the 'centimeter' plot `red` and in the 'meter' plot `blue`. **

This is best done with the `%T>%` pipe:
```{r}
boys %>%
  subset(select = c(hgt, wgt)) %T>%
  plot(col = "red", main = "Height in centimeters") %>%
  transform(hgt = hgt / 100) %>%
  plot(col = "blue", main = "Height in meters")
```

The `%T>%` pipe is very useful, because it creates a literal `T` junction in the pipe. It is perhaps most informative to graphically represent the above pipe as follows:
```{r eval=FALSE}
boys %>%
  subset(select = c(hgt, wgt)) %T>%
  plot(col = "red", main = "Height in centimeters") %>%
  transform(hgt = hgt / 100) %>%
  plot(col = "blue", main = "Height in meters")
```
![](flow_t_pipe.png)

We can see that there is indeed a literal T-junction. Naturally, we can expand this process with more `%T>%` pipes. However, once a pipe gets too long or too complicated, it is perhaps more useful to cut the piped problem into smaller, manageble pieces. 

---

```{r echo=FALSE}
set.seed(32083)
x <- rnorm(100, mean=3, sd=7)
save(x, file = "Exercise4_data.RData")
```


In the following experiment we investigate least-squares estimation of the mean. The data for this experiment can be found in the workspace [`Exercise4_data.RData`](Exercise4_data.RData). Either download this workspace and manually `load()` it into `R`, or run the below connection:

```{r eval=FALSE}
con <- url("https://www.gerkovink.com/fundamentals/Wk2/Exercise/Exercise4_data.RData")
load(con)
```


---

7. **Start by drawing a 100 values from a normal distribution with $\mu = 3$ and $\sigma = 7$. Use seed value `32083`.**


```{r}
set.seed(32083)

x <- rnorm(100, mean=3, sd=7)
```

---

8. **Next, confirm that the sample mean of the values in x is near 4.166.**
```{r}
mean(x)
```

---

9. **Calculate the sample mean's sum of squared deviations from $\mu$. The sum of squared deviations from mu is defined as: **
$$ \sum_{i=1}^{100} (x_i - \mu)^2,$$
There is a slow way
```{r}
mu = 3
summed <- x-mu
sum.sq <- sum(summed^2)
```

And a fast way
```{r}
sum.sq2 <- apply(outer(x, mu, "-")^2, 2, sum)
```
Both solutions are identical
```{r}
identical(sum.sq, sum.sq2)
```

---

10. **Now create a function that automates the calculation of the sum of squares for any given $\mu$. Call the function `lsfun` because we are going to identify the least squares estimate in exercise 8.**

```{r eval=printAnswers}
lsfun <- function(meanest) apply(outer(x, meanest, "-")^2, 2, sum)
```

or, 100% equivalently, but easier to spot as a function:
```{r}
lsfun <- function(meanest){
  apply(outer(x, meanest, "-")^2, 2, sum)
}
```

---

11. **Plot the curve of your least square function such that you can identify the minimum of the curve (i.e. the location for $x$ where the sum of the squared deviations are the lowest).**
```{r}
curve(lsfun, from = 4.16, to = 4.17)
```

---


12. **Repeat the experiment from 10 with the following $X \sim \mathcal{N}(\mu, \sigma^2)$ normal samples of length $n=100$, but now use the sample mean $\bar{x}$ in your function `lsfun()`. Let the function plot the curve and print the location where the minimum of the sum of the squares is located each time. Fix the seed to `set.seed(123)`:**

- $x \sim \mathcal{N}(3, 7)$
- $x \sim \mathcal{N}(15, 12)$
- $x \sim \mathcal{N}(0, 2)$
- $\sqrt{x} \sim \mathcal{N}(0, 2)$, i.e. you need to square $x$

Hint: use the sample mean $\bar{x}$ as the center of your graph and add/subtract e.g. `.5` from this value to plot a range.

First, we fix the random seed
```{r}
set.seed(123)
```

Code-wise it is efficient to write a function that does the repetitive experimentation. That way we have to write some lines of code only once. 
```{r}
plotfun <- function(x, meanest, plot = TRUE){
  xbar <- mean(x)
  lsfun <- function(meanest){ apply(outer(xbar, meanest, "-")^2, 2, sum)}
  # lsfun <- function(mu, xbar) {
  #   summed <- x-mu
  #   sum.sq <- sum(summed^2)
  #   return(sum.sq)
  # }
  if (plot) {
    curve(lsfun, from = xbar - .5, to = xbar + .5, 
          ylab=expression(paste(Sigma," ",e^2))) #nicer y-axis label
  }
  return(cat("The mean is:", xbar, "\n"))
}
```

- For $x \sim \mathcal{N}(3, 7)$:
```{r eval=printAnswers, echo=printAnswers}
rnorm(100, mean=3, sd=sqrt(7)) %>%
  plotfun(meanest = 3, plot = TRUE)
```

- For $x \sim \mathcal{N}(15, 12)$
```{r eval=printAnswers, echo=printAnswers}
rnorm(100, mean=15, sd=sqrt(12)) %>%
  plotfun(meanest = 15, plot = TRUE)
```

- For $x \sim \mathcal{N}(0, 2)$:
```{r eval=printAnswers, echo=printAnswers}
rnorm(100, mean=0, sd=2) %>%
  plotfun(meanest = 0, plot = TRUE)
```

- For $\sqrt{x} \sim \mathcal{N}(0, 2)$:
```{r eval=printAnswers, echo=printAnswers}
rnorm(100, mean=0, sd=2)^2 %>%
  plotfun(meanest = 0, plot = TRUE)
```


---

End of practical. 

 
---

#### Useful References

- [`magrittr`](https://magrittr.tidyverse.org)
- [`R` for Data Science](http://r4ds.had.co.nz) - [Chapter 18 on pipes](http://r4ds.had.co.nz/pipes.html)